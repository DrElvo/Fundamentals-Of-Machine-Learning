{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_lOk-oKqq89E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec778f04-493d-4e44-cd93-f2bf86090c84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Accuracy on the training set FOREST: 78.125%\n",
            "Accuracy on the validation set FOREST: 81.16666666666667%\n"
          ]
        }
      ],
      "source": [
        "#This is the version used to create the predictions file\n",
        "\n",
        "#All imports used to create the classifier and preprocess the data.\n",
        "\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') #Mounting the drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Loading of the data into the Pandas dataframe\n",
        "training_data_1 = pd.read_csv('gdrive/My Drive/Colab/FML/training1.csv') #I named the folder inside the google drive FML, if your testing the code this is the only section that might need to be changed in order to import the data.\n",
        "training_data_2 = pd.read_csv('gdrive/My Drive/Colab/FML/training2.csv')\n",
        "testing_data_1 = pd.read_csv('gdrive/My Drive/Colab/FML/test.csv')\n",
        "\n",
        "#This version splits the data into two seperate sets of data, and then concatenates them again. They train on the same Random Forest model, which out of the three tested below provieded the best result. This is the version that provides the data for the testing\n",
        "\n",
        "#Splits the first set of training data into CNN and GIST features, this is not entirely necessary in this version as it was both used on the same model later.\n",
        "X_train_cnn_1 = training_data_1.iloc[:, :2048]\n",
        "X_train_gist_1 = training_data_1.iloc[:, 2048:-2]\n",
        "Y_train_1 = training_data_1.iloc[:, -2]\n",
        "confidence_weights1 = training_data_1.iloc[:, -1]\n",
        "confidence_weights1 = (confidence_weights1 - 0.66) / 0.34#Splits the  confidence rating into Binary values\n",
        "\n",
        "#Splits the second set of training data into CNN and GIST features, this is not entirely necessary in this version as it was both used on the same model later.\n",
        "X_train_cnn_2 = training_data_2.iloc[:, :2048]\n",
        "X_train_gist_2 = training_data_2.iloc[:, 2048:-2]\n",
        "Y_train_2 = training_data_2.iloc[:, -2]\n",
        "confidence_weights2 = training_data_2.iloc[:, -1]\n",
        "confidence_weights2 = (confidence_weights2 - 0.66) / 0.34#Splits the  confidence rating into Binary values\n",
        "\n",
        "#Concatenate the two seperate training data sets into CNN and GIST features seperately. Splitting them wasn't entirely necessary because in the end i didn't train seperate classifiers on the two data types\n",
        "X_train_cnn = np.concatenate((X_train_cnn_1, X_train_cnn_2), axis=0)#concatenates the CNN data from training set one\n",
        "X_train_gist = np.concatenate((X_train_gist_1, X_train_gist_2), axis=0)#concatenates the CNN data from training set two\n",
        "Y_train = np.concatenate((Y_train_1, Y_train_2), axis=0)#concatenates the Y data from training set one and two\n",
        "confidence_weights = np.concatenate((confidence_weights1, confidence_weights2), axis=0)#concatenates the confidence weights\n",
        "\n",
        "#Concatenate the CNN and GIST features as both will be used to train the same model\n",
        "X_train = np.concatenate((X_train_cnn, X_train_gist), axis=1) \n",
        "\n",
        "#Splits the data into a training set and a validation set\n",
        "X_trainable, X_validation, Y_trainable, Y_validation, confidence_train, confidence_val = train_test_split(X_train, Y_train, confidence_weights,  random_state=6014, test_size=0.2) #The model was tuned to this specific seed to give the best result, as well as this the split size was also tuned for the best result\n",
        "\n",
        "#Applies the Imputer to the data, replacing the gaps with the median values of the values around it. This provides a better result than the standard mean application\n",
        "IMP = SimpleImputer(strategy='median')#creates the Imputer. Uses median instead of mean, this generally gave a better result on different seeds and tunings.\n",
        "X_trainable = IMP.fit_transform(X_trainable)#fits and then transforms the training data using the imputer\n",
        "X_validation = IMP.transform(X_validation)#transforms the validation set\n",
        "\n",
        "\n",
        "#Uses the scaler as a form of preprocessing on the data. Applied the confidence weights to the values as well \n",
        "SCA = StandardScaler()#creates the scaler, no parameter tuning.\n",
        "X_trainable = SCA.fit_transform(X_trainable,sample_weight=confidence_train)#transforms and then fits the data on the scaler\n",
        "X_validation = SCA.transform(X_validation)#transforms the validation set, doesn't fit it\n",
        "\n",
        "\n",
        "#Set up the testing data using the trained Scaler and Imputer\n",
        "X_test_cnn = testing_data_1.iloc[:, :2048]\n",
        "X_test_gist = testing_data_1.iloc[:, 2048:]\n",
        "X_test = np.concatenate((X_test_cnn, X_test_gist), axis=1)\n",
        "X_test = IMP.transform(X_test)#Imputes the data using the imputer trained from the training data\n",
        "X_test = SCA.transform(X_test)#Scales the data using the same imputer trained from the training data\n",
        "\n",
        "class_weights = {0: 1, 1: 1} #The class weights were tested in the Logistic Regression model, however \n",
        "\n",
        "classifier_3 = RandomForestClassifier(n_estimators=300, max_depth=19, min_samples_split=25, random_state=6014, max_features=\"sqrt\")\n",
        "#(n_estimators=152, max_depth=11, min_samples_split=5, random_state=9876543, max_features=\"sqrt\") This was the first best attempt I had at tuning, after using the grid search from SKLearn and manual tuning\n",
        "#(n_estimators=300, max_depth=19, min_samples_split=25, random_state=6014, max_features=\"sqrt\") This was the best attempt i managed to get after doing mainly manual tuning\n",
        "\n",
        "#Fitting the classifier with the trainable data set\n",
        "classifier_3.fit(X_trainable, Y_trainable, sample_weight=confidence_train) #The parameters are that of the split data, only putting in the trainable data to fit the inital model.\n",
        "\n",
        "#predict the testing data using the classifier and upload it back to the same folder of which the data was imported from\n",
        "Y_prediction = classifier_3.predict(X_test)\n",
        "with open('gdrive/My Drive/Colab/FML/predictions.csv', 'w', encoding = 'utf-8-sig') as f:\n",
        "  Y_prediction = pd.DataFrame(Y_prediction, columns = ['prediction'])#names the column predicition\n",
        "  Y_prediction.to_csv(f,index=False)\n",
        "\n",
        "#predicting the data for the trainable and validation set, checking for overfitting using the training set and getting an estimate for the accuracy on the validation set\n",
        "trainable_prediction = classifier_3.predict(X_trainable)\n",
        "validation_prediction = classifier_3.predict(X_validation)\n",
        "\n",
        "#Compare training and validation data sets\n",
        "accuracy = np.mean(Y_trainable == trainable_prediction)\n",
        "print(f\"Accuracy on the training set FOREST: {accuracy*100}%\") #these lines paste the training accuracy\n",
        "\n",
        "accuracy2 = np.mean(Y_validation == validation_prediction)\n",
        "print(f\"Accuracy on the validation set FOREST: {accuracy2*100}%\") #these lines paste the validation accuracy"
      ]
    }
  ]
}